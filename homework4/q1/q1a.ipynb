{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--XItMxuyuwY"
      },
      "source": [
        "#### Check if GPU is available\n",
        "If you are running this in gsds server, follow the instruction below to run jupyter notebook with GPU.\n",
        "\n",
        "https://gsds.gitbook.io/gsds/for-beginners/slurm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Install requried packages if not installed in your environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NgOYc32SGNgu"
      },
      "outputs": [],
      "source": [
        "!pip install wikipedia\n",
        "!pip install transformers\n",
        "!pip install -q datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Run this cell before you start"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "from collections import OrderedDict\n",
        "import wikipedia as wiki\n",
        "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbC_lmmut0sf"
      },
      "source": [
        "# 1. Inference using a pre-trained Question Answering model \n",
        "\n",
        "In this problem, we will utilize a pre-trained BERT(Bidirectional Encoder Representations from Transformers) model for question answering. BERT excels in this task by leveraging its contextual understanding of language, employing techniques such as tokenization, segment embeddings, positional embeddings, and multi-head self-attention to capture intricate relationships between words. During the inference phase, the model predicts answer spans in a passage based on its extensive pre-trained knowledge and fine-tuned task-specific understanding. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Twl2XFHPT1Lw"
      },
      "source": [
        "![1_cXDOP0gsE7Zp8-sgZqYfTA.webp](data:image/webp;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGLo5qxOUdVt"
      },
      "source": [
        "There are various approaches to employing deep learning models for question answering, and we will explore the intricacies of this task in upcoming lectures. For now, prepare for a hands-on journey into loading a pre-trained BERT model from Hugging Face, which encodes questions and context together and answers by selecting a span in the given context. The model's output includes scores for the start and end positions of the answer span. Follow the instructions in the provided Jupyter notebook to complete the code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbF3j0paCyCa"
      },
      "source": [
        "**(a)** Load the pre-trained model and tokenizer and complete the `__init__` function. **(2 pts)**\n",
        "\n",
        "**(b)** Implement the `tokenize` function to encode the question and context. **(6 pts)**\n",
        "\n",
        "**(c)** Complete the `generateAnswer` function for inference. **(12 pts)**\n",
        "\n",
        "**(d, bonus)** Add a condition that ensures the end position comes after the start position in your inference code. **(4 pts)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cLypk7wBF2_3"
      },
      "outputs": [],
      "source": [
        "class QAmodel:\n",
        "    def __init__(self, model_path):\n",
        "        self.model_path = model_path\n",
        "\n",
        "        ### YOUR CODE HERE (~2 lines)\n",
        "        ### TODO:\n",
        "        ### Load a tokenizer and question answering model from hugging face and save them in self.tokenizer and self.model\n",
        "        ### Hint: you can refer to the following document and use given model_path\n",
        "        ### https://huggingface.co/docs/transformers/model_doc/auto#transformers.AutoModelForQuestionAnswering\n",
        "        \n",
        "\n",
        "        \n",
        "        ### END YOUR CODE\n",
        "        self.max_seq_len = self.model.config.max_position_embeddings\n",
        "        self.splitted = False\n",
        "\n",
        "    def tokenize(self, question, context):\n",
        "        ### YOUR CODE HERE (~5 lines)\n",
        "        ### TODO:\n",
        "        ### 1. Encode the question and context by passing into the loaded tokenizer and save it to self.inputs\n",
        "        ###     Hint: you have to return 'token_type_ids' in order to be used in self.split()\n",
        "        ###     Hint: you can refer to the following document for tokenizer\n",
        "        ###           https://huggingface.co/transformers/v2.11.0/main_classes/tokenizer.html\n",
        "        ### 2. If input length exceeds the maximum sequence length, the input context should be splitted. Mark self.splitted True if it is splitted.\n",
        "        ###     Hint: use given self.max_seq_len and self.split()\n",
        "        ### Hint: this function will return nothing\n",
        "        \n",
        "\n",
        "\n",
        "        ### END YOUR CODE\n",
        "\n",
        "    def split(self):\n",
        "        # this function is to split the input context if the length exceeds the maximum sequence length\n",
        "        question_mask = self.inputs['token_type_ids'].lt(1)\n",
        "        question_size = torch.masked_select(self.inputs['input_ids'], question_mask).size()[0]\n",
        "        split_size = self.max_seq_len - question_size - 1\n",
        "\n",
        "        inputs_splitted = OrderedDict()\n",
        "        for key, item in self.inputs.items():\n",
        "            question = torch.masked_select(item, question_mask)\n",
        "            context = torch.masked_select(item, ~question_mask)\n",
        "            context_splitted = torch.split(context, split_size)\n",
        "\n",
        "            for i, context in enumerate(context_splitted):\n",
        "                if i not in inputs_splitted:\n",
        "                    inputs_splitted[i] = {}\n",
        "                input_item = torch.cat((question, context))\n",
        "                if i != len(context_splitted) - 1:\n",
        "                    if key == 'input_ids':\n",
        "                        input_item = torch.cat((input_item, torch.tensor([102])))\n",
        "                    else:\n",
        "                        input_item = torch.cat((input_item, torch.tensor([1])))\n",
        "                inputs_splitted[i][key] = torch.unsqueeze(input_item, dim=0)\n",
        "\n",
        "        return inputs_splitted\n",
        "\n",
        "    def generateAnswer(self):\n",
        "        if self.splitted:\n",
        "            answer = ''\n",
        "            for i, input_item in self.inputs.items():\n",
        "\n",
        "                ### YOUR CODE HERE (~6 lines)\n",
        "                ### TODO:\n",
        "                ### Get answer from each of the splitted contexts. \n",
        "                ### Remember that this model predicts answer by span selection. The output will contain scores for start and end position. \n",
        "                ### Hint: Use torch.argmax and given self.convert_to_string function\n",
        "                ### Hint: You should note that in a Python index [A:B], it includes the element at index A and excludes the element at index B.\n",
        "                ### Hint: you can refer to the following document \n",
        "\n",
        " \n",
        "\n",
        "                ### END YOUR CODE\n",
        "                if ans != '[CLS]':\n",
        "                    answer += ans + \", \"\n",
        "            return answer\n",
        "        \n",
        "        else:\n",
        "            ### YOUR CODE HERE (~6 lines)\n",
        "            ### TODO:\n",
        "            ### Get answer from self.inputs.\n",
        "            ### Hint: use the same approach you made in the previous question\n",
        "\n",
        "\n",
        "\n",
        "            ### END YOUR CODE\n",
        "            return answer\n",
        "\n",
        "    def convert_to_string(self, input_ids):\n",
        "        tokens = self.tokenizer.convert_ids_to_tokens(input_ids)\n",
        "        answer = self.tokenizer.convert_tokens_to_string(tokens)\n",
        "        return answer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xb5uAIjaFPkV"
      },
      "source": [
        "### Inference\n",
        "\n",
        "Now let's use the pre-trained model to generate answer to the questions. \n",
        "\n",
        "For context, we will use Wikipedia, a Python library that makes it easy to access and parse data from Wikipedia.\n",
        "You can refer to [here](https://wikipedia.readthedocs.io/en/latest/code.html#api) for use of the library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wOA1HqIcGAXA"
      },
      "outputs": [],
      "source": [
        "questions = [\n",
        "    'Who is the author of Harry Potter and the Goblet of Fire?',\n",
        "    'Where was the 2010 world cup played?'\n",
        "    ]\n",
        "\n",
        "model_path = \"deepset/bert-base-cased-squad2\"\n",
        "model = QAmodel(model_path)\n",
        "\n",
        "for question in questions:\n",
        "    print(f\"Question: {question}\")\n",
        "    results = wiki.search(question)\n",
        "\n",
        "    page = wiki.page(results[0])\n",
        "    print(f\"Top wiki result: {page}\")\n",
        "    context = page.content\n",
        "\n",
        "    model.tokenize(question, context)\n",
        "    answer = model.generateAnswer()\n",
        "    print(f\"Answer: {answer}\")\n",
        "    print(\"---------------------------------------------------------------------------------\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
